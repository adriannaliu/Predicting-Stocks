{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('dataset/news_sentiment_augmented_google.csv').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "df['Middle'] = (df['Low'] + df['High']) / 2\n",
    "df = df.drop(['Date'], axis=1)\n",
    "\n",
    "training_data = df[:300]\n",
    "validation_data = df[300:400]\n",
    "testing_data = df[400:]\n",
    "\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_data_scaled = pd.DataFrame(sc.fit_transform(training_data),\n",
    "              columns=training_data.columns,\n",
    "              dtype='float64')\n",
    "validation_data_scaled = pd.DataFrame(sc.transform(validation_data),\n",
    "              columns=training_data.columns,\n",
    "              dtype='float64')\n",
    "testing_data_scaled = pd.DataFrame(sc.transform(testing_data),\n",
    "              columns=training_data.columns,\n",
    "              dtype='float64')\n",
    "\n",
    "def create_dataset(dataset, target_feature, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(look_back, len(dataset)):\n",
    "        a = dataset.drop([target_feature], axis=1).iloc[i - look_back:i].values[0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset.iloc[i][target_feature])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = create_dataset(training_data_scaled, 'Middle', look_back=1)\n",
    "valX, valY = create_dataset(validation_data_scaled, 'Middle', look_back=1)\n",
    "\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(training_data_scaled, 'Middle', look_back=1)\n",
    "valX, valY = create_dataset(validation_data_scaled, 'Middle', look_back=1)\n",
    "\n",
    "num_feat = trainX.shape[1]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], look_back, num_feat))\n",
    "valX = np.reshape(valX, (valX.shape[0], look_back, num_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.54315305, 0.22760467, 0.19798   , ..., 0.06163006,\n",
       "         0.0849544 , 0.        ]],\n",
       "\n",
       "       [[0.4469697 , 0.51282051, 0.1032371 , ..., 0.05880761,\n",
       "         0.08682293, 0.        ]],\n",
       "\n",
       "       [[0.72318693, 0.60177182, 0.19313457, ..., 0.06812558,\n",
       "         0.11905095, 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.17585693, 0.50283733, 0.55595714, ..., 0.97513919,\n",
       "         0.11363767, 0.        ]],\n",
       "\n",
       "       [[0.16761364, 0.41766827, 0.37746063, ..., 0.93987782,\n",
       "         0.14854818, 0.        ]],\n",
       "\n",
       "       [[0.        , 0.19042232, 0.45242139, ..., 0.90844417,\n",
       "         0.14450546, 0.        ]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
